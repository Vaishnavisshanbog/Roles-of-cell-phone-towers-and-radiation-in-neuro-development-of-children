{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d469075-1410-4f02-90d6-4b5e9306a3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "import statsmodels.api as sm\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, MaxPooling1D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "import seaborn as sns\n",
    "\n",
    "# Load and clean dataset\n",
    "file_path = \"Book1_vashnvi.xlsx\"\n",
    "data = pd.read_excel(file_path, header=1)  # Load with the second row as the header\n",
    "data.columns = ['Index', 'ChildsName', 'LORRoom1', 'GrossMotor', 'FineMotor', 'SleepDisorder']  # Rename columns\n",
    "\n",
    "# Drop unnecessary column\n",
    "data.drop(columns=['Index'], inplace=True)\n",
    "\n",
    "# Replace empty strings with NaN and define numeric columns\n",
    "data.replace(\"\", np.nan, inplace=True)\n",
    "numeric_cols = ['LORRoom1', 'GrossMotor', 'FineMotor', 'SleepDisorder']\n",
    "\n",
    "# Convert specified columns to numeric, coercing errors to NaN\n",
    "data[numeric_cols] = data[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Enhanced imputation with median\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "data[numeric_cols] = imputer.fit_transform(data[numeric_cols])\n",
    "\n",
    "# Display dataset summary\n",
    "print(\"\\nCleaned Data Overview:\")\n",
    "print(data.info())\n",
    "print(data.describe())\n",
    "\n",
    "# Define features and target\n",
    "X = data[['LORRoom1', 'GrossMotor', 'FineMotor']]\n",
    "y = data['SleepDisorder']\n",
    "\n",
    "# Step 1: Polynomial Regression with Stepwise Selection\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly.fit_transform(X)\n",
    "X_poly = sm.add_constant(X_poly)\n",
    "poly_model = sm.OLS(y, X_poly).fit()\n",
    "\n",
    "# Stepwise feature elimination based on p-values\n",
    "p_threshold = 0.05  # Set the threshold to 0.05\n",
    "while True:\n",
    "    p_values = poly_model.pvalues\n",
    "    max_p_value = p_values.max()  # Find the maximum p-value\n",
    "    if max_p_value > p_threshold:\n",
    "        max_p_feature = p_values.idxmax()  # Feature with the highest p-value\n",
    "        feature_index = p_values.index.get_loc(max_p_feature)\n",
    "        X_poly = np.delete(X_poly, feature_index, axis=1)  # Remove feature with high p-value\n",
    "        poly_model = sm.OLS(y, X_poly).fit()  # Re-fit the model with the remaining features\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print(\"\\nPolynomial Regression OLS Summary (Post Feature Selection):\")\n",
    "print(poly_model.summary())\n",
    "\n",
    "# Step 2: Regularization Techniques (Ridge and Lasso)\n",
    "ridge = Ridge()\n",
    "lasso = Lasso()\n",
    "ridge_params = {'alpha': [1e-6, 1e-3, 1, 10, 100]}\n",
    "lasso_params = {'alpha': [1e-6, 1e-3, 1, 10, 100]}\n",
    "\n",
    "ridge_grid = GridSearchCV(ridge, ridge_params, cv=5, scoring='neg_mean_squared_error')\n",
    "lasso_grid = GridSearchCV(lasso, lasso_params, cv=5, scoring='neg_mean_squared_error')\n",
    "ridge_grid.fit(X_poly, y)\n",
    "lasso_grid.fit(X_poly, y)\n",
    "\n",
    "print(\"\\nBest Ridge Alpha:\", ridge_grid.best_params_)\n",
    "print(\"Best Lasso Alpha:\", lasso_grid.best_params_)\n",
    "\n",
    "# Step 3: Decision Tree Regressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Decision Tree Regressor\n",
    "tree_model = DecisionTreeRegressor(max_depth=5, random_state=42)  # You can adjust max_depth to control overfitting\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_tree = tree_model.predict(X_test)\n",
    "\n",
    "# Calculate the Mean Squared Error (MSE) to evaluate the model's performance\n",
    "mse_tree = mean_squared_error(y_test, y_pred_tree)\n",
    "print(f\"Decision Tree MSE: {mse_tree:.4f}\")\n",
    "\n",
    "# Plotting the predictions vs true values for better visualization\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred_tree, color='blue', alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--')  # Identity line\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.title('Decision Tree Regression: True Values vs Predicted Values')\n",
    "plt.show()\n",
    "\n",
    "# You can also visualize the decision tree itself\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_tree(tree_model, filled=True, feature_names=X.columns, fontsize=10)\n",
    "plt.title('Decision Tree Model Visualization')\n",
    "plt.show()\n",
    "\n",
    "# Step 4: Improved CNN Approach\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "X_train_cnn = X_train.reshape(-1, 1, X_train.shape[1])\n",
    "X_test_cnn = X_test.reshape(-1, 1, X_test.shape[1])\n",
    "\n",
    "# Define the CNN model\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(filters=32, kernel_size=1, activation='relu', input_shape=(1, X_train.shape[1])),\n",
    "    MaxPooling1D(pool_size=1),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1)  # Output layer for regression\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer=Adam(learning_rate=0.0001), loss=MeanSquaredError())\n",
    "history = cnn_model.fit(X_train_cnn, y_train, epochs=100, batch_size=8, validation_data=(X_test_cnn, y_test), verbose=1)\n",
    "\n",
    "# Step 5: Evaluate CNN Model\n",
    "y_pred_cnn_continuous = cnn_model.predict(X_test_cnn).flatten()\n",
    "threshold = np.median(y_train)\n",
    "y_pred_cnn_binary = (y_pred_cnn_continuous > threshold).astype(int)\n",
    "y_test_binary = (y_test > threshold).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_test_binary, y_pred_cnn_binary)\n",
    "precision = precision_score(y_test_binary, y_pred_cnn_binary)\n",
    "recall = recall_score(y_test_binary, y_pred_cnn_binary)\n",
    "f1 = f1_score(y_test_binary, y_pred_cnn_binary)\n",
    "\n",
    "print(\"\\nCNN Model Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Plot Training and Validation Loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss over Epochs')\n",
    "plt.show()\n",
    "\n",
    "# Visualization: Scatter Plots\n",
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(data['LORRoom1'], data['GrossMotor'], color='blue', alpha=0.5, label='Gross Motor')\n",
    "plt.xlabel(\"LORRoom1\")\n",
    "plt.ylabel(\"Gross Motor Score\")\n",
    "plt.title(\"LORRoom1 vs Gross Motor\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(data['LORRoom1'], data['FineMotor'], color='green', alpha=0.5, label='Fine Motor')\n",
    "plt.xlabel(\"LORRoom1\")\n",
    "plt.ylabel(\"Fine Motor Score\")\n",
    "plt.title(\"LORRoom1 vs Fine Motor\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(data['LORRoom1'], data['SleepDisorder'], color='red', alpha=0.5, label='Sleep Disorder')\n",
    "\n",
    "plt.xlabel(\"LORRoom1\")\n",
    "plt.ylabel(\"Sleep Disorder Score\")\n",
    "plt.title(\"LORRoom1 vs Sleep Disorder\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation Heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation_matrix = data[numeric_cols].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title(\"Correlation Heatmap of Numeric Features\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
